{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.cloud import bigquery\n",
        "# IMPORTANT: Use your project ID here\n",
        "PROJECT_ID = 'mgmt-544-544'\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "print(\"Authentication and client initialization successful.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmSe2eo-HYjT",
        "outputId": "cb6bbb20-091c-4c3b-9b02-7aa170fdd5aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authentication and client initialization successful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIRrXDKlF6yF",
        "outputId": "56a425e8-16bc-4e78-e9ae-51603a315e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.12/dist-packages (3.38.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.11.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (2.28.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.38.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
            "Requirement already satisfied: packaging>=24.2.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (25.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.32.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.26.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (4.9.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery) (1.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio<2.0.0,>=1.33.2->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (4.15.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.6.1)\n",
            "Project ID: mgmt-544-544\n",
            "Target Table: `mgmt-544-544.us_flights_kaggle.flights`\n"
          ]
        }
      ],
      "source": [
        "# 1. Install the BigQuery library\n",
        "!pip install google-cloud-bigquery pandas\n",
        "\n",
        "# 2. Import libraries\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 3. Set your project ID\n",
        "# IMPORTANT: Replace 'YOUR_GCP_PROJECT_ID' with your actual Google Cloud Project ID\n",
        "PROJECT_ID = 'mgmt-544-544'\n",
        "\n",
        "# Set the dataset prefix for easy reference\n",
        "DATASET_PREFIX = f\"{PROJECT_ID}.us_flights_kaggle\"\n",
        "TABLE_NAME = f\"`{DATASET_PREFIX}.flights`\"\n",
        "\n",
        "# Initialize the BigQuery Client\n",
        "# This will usually trigger an authentication prompt in Colab\n",
        "# or use your service account credentials if set up.\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "print(f\"Project ID: {PROJECT_ID}\")\n",
        "print(f\"Target Table: {TABLE_NAME}\")\n",
        "\n",
        "# Corrected column names based on your previous attempts\n",
        "DELAY_LABEL = 'ArrDelay'\n",
        "DEP_DELAY = 'DepDelay'\n",
        "CARRIER_FEATURE = 'Reporting_Airline'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"CREATE OR REPLACE MODEL\n",
        "  mgmt-544-544.us_flights_kaggle.flight_arr_delay_model\n",
        "OPTIONS\n",
        "  (model_type='LINEAR_REG',\n",
        "    input_label_cols=['ArrDelay'],\n",
        "    data_split_method='AUTO_SPLIT'\n",
        "  ) AS\n",
        "SELECT\n",
        "  ArrDelay,\n",
        "  DepDelay,\n",
        "  distance,\n",
        "  Reporting_Airline,\n",
        "  origin,\n",
        "  dest,\n",
        "  dayofweek\n",
        "FROM\n",
        "  `mgmt-544-544.us_flights_kaggle.flights`\n",
        "-- Filter out nulls\n",
        "WHERE ArrDelay IS NOT NULL\n",
        "  AND DepDelay IS NOT NULL\n",
        "  AND distance IS NOT NULL\n",
        "  AND Reporting_Airline IS NOT NULL\n",
        "  AND origin IS NOT NULL\n",
        "  AND dest IS NOT NULL\n",
        "  AND dayofweek IS NOT NULL\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "hZ_0GW4eGNm6",
        "outputId": "813cc165-2547-410e-f553-9811795c6de6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"CREATE OR REPLACE MODEL\\n  mgmt-544-544.us_flights_kaggle.flight_arr_delay_model\\nOPTIONS\\n  (model_type='LINEAR_REG',\\n    input_label_cols=['ArrDelay'],\\n    data_split_method='AUTO_SPLIT'\\n  ) AS\\nSELECT\\n  ArrDelay,\\n  DepDelay,\\n  distance,\\n  Reporting_Airline,\\n  origin,\\n  dest,\\n  dayofweek\\nFROM\\n  `mgmt-544-544.us_flights_kaggle.flights`\\n-- Filter out nulls\\nWHERE ArrDelay IS NOT NULL \\n  AND DepDelay IS NOT NULL\\n  AND distance IS NOT NULL\\n  AND Reporting_Airline IS NOT NULL\\n  AND origin IS NOT NULL\\n  AND dest IS NOT NULL\\n  AND dayofweek IS NOT NULL\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluate the Model (ML.EVALUATE)\n",
        "evaluation_sql = \"\"\"\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.EVALUATE(MODEL `mgmt-544-544.us_flights_kaggle.flight_arr_delay_model`)\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n--- Model Evaluation (MAE, RMSE) ---\")\n",
        "df_eval = client.query(evaluation_sql).to_dataframe()\n",
        "print(df_eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71szAn9bHQJ1",
        "outputId": "70777c3d-79a3-4bb4-c48b-b0ac4f0fe815"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Evaluation (MAE, RMSE) ---\n",
            "   mean_absolute_error  mean_squared_error  mean_squared_log_error  \\\n",
            "0              8.64908          155.877725                1.389387   \n",
            "\n",
            "   median_absolute_error  r2_score  explained_variance  \n",
            "0               6.372521  0.866472            0.866487  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean abosolute error is  on average, how many minutes the model's predicted arrival delay deviates from the actual arrival delay.In this case, this model's prediction will most likely be off by 8.649 minutes.Lower MAE means better model performance."
      ],
      "metadata": {
        "id": "sBqJmdnEHjO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ML.EXPLAIN_PREDICT Query for Regression Model\n",
        "\n",
        "# Define the SQL query as a multi-line Python string\n",
        "regression_explain_sql = \"\"\"\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.EXPLAIN_PREDICT(MODEL `mgmt-544-544.us_flights_kaggle.flight_arr_delay_model`,\n",
        "  (\n",
        "    -- Hypothetical Flight 1: Early departure, long distance, major carrier\n",
        "    SELECT\n",
        "      -10 AS DepDelay,\n",
        "      2500 AS distance,\n",
        "      'AA' AS Reporting_Airline,\n",
        "      'JFK' AS origin,\n",
        "      'LAX' AS dest,\n",
        "      3 AS dayofweek\n",
        "    UNION ALL\n",
        "    -- Hypothetical Flight 2: Delayed departure, short distance, regional carrier\n",
        "    SELECT\n",
        "      45 AS DepDelay,\n",
        "      300 AS distance,\n",
        "      'MQ' AS Reporting_Airline,\n",
        "      'DFW' AS origin,\n",
        "      'HOU' AS dest,\n",
        "      5 AS dayofweek\n",
        "  )\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query and fetch results into a Pandas DataFrame\n",
        "print(\"Running ML.EXPLAIN_PREDICT on two hypothetical flights...\")\n",
        "df_regression_explain = client.query(regression_explain_sql).to_dataframe()\n",
        "\n",
        "print(\"\\n--- ML.EXPLAIN_PREDICT Results ---\")\n",
        "print(df_regression_explain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vumHQx6VHw6g",
        "outputId": "1f5a42a3-18a7-4b8d-95e7-5d1bfe668b05"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running ML.EXPLAIN_PREDICT on two hypothetical flights...\n",
            "\n",
            "--- ML.EXPLAIN_PREDICT Results ---\n",
            "   predicted_ArrDelay                           top_feature_attributions  \\\n",
            "0          -16.163630  [{'feature': 'Reporting_Airline', 'attribution...   \n",
            "1           43.859188  [{'feature': 'Reporting_Airline', 'attribution...   \n",
            "\n",
            "   baseline_prediction_value  prediction_value  approximation_error  DepDelay  \\\n",
            "0               -6268.052829        -16.163630                  0.0       -10   \n",
            "1               -6268.052829         43.859188                  0.0        45   \n",
            "\n",
            "   distance Reporting_Airline origin dest  dayofweek  \n",
            "0      2500                AA    JFK  LAX          3  \n",
            "1       300                MQ    DFW  HOU          5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flight 1: There is a 10 minute early departure, the flight is 2500 miles, it's American Airlines, and the flight is going from JFK to LAX\n",
        "Flight 2: There is a 45 minute delayed departure, 300 mile flight, it's on a Friday, and it's by MQ aka Envoy Air."
      ],
      "metadata": {
        "id": "in-CT2UnH88M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2"
      ],
      "metadata": {
        "id": "Lqjp0JMaLBUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2A. Corrected Training SQL (Fixes Invalid cast from FLOAT64 to BOOL)\n",
        "CLASSIFICATION_MODEL_BASE = \"mgmt-544-544.us_flights_kaggle.flight_diverted_model_base\"\n",
        "\n",
        "classification_train_base_sql = f\"\"\"\n",
        "CREATE OR REPLACE MODEL\n",
        "  `{CLASSIFICATION_MODEL_BASE}`\n",
        "OPTIONS\n",
        "  (model_type='LOGISTIC_REG',\n",
        "    input_label_cols=['is_diverted'],\n",
        "    data_split_method='AUTO_SPLIT'\n",
        "  ) AS\n",
        "SELECT\n",
        "  -- Use a logical expression to safely convert the 0/1 FLOAT64 into a BOOLEAN\n",
        "  (diverted = 1) AS is_diverted,\n",
        "  DepDelay,\n",
        "  distance,\n",
        "  Reporting_Airline,\n",
        "  origin,\n",
        "  dest,\n",
        "  dayofweek\n",
        "FROM\n",
        "  `mgmt-544-544.us_flights_kaggle.flights`\n",
        "-- Ensure you also filter out rows where 'diverted' itself might be NULL\n",
        "WHERE diverted IS NOT NULL\n",
        "  AND DepDelay IS NOT NULL\n",
        "  AND distance IS NOT NULL\n",
        "  AND Reporting_Airline IS NOT NULL\n",
        "  AND origin IS NOT NULL\n",
        "  AND dest IS NOT NULL\n",
        "  AND dayofweek IS NOT NULL\n",
        "\"\"\"\n",
        "\n",
        "print(f\"\\nRetrying Training Baseline Classification Model: {CLASSIFICATION_MODEL_BASE}...\")\n",
        "query_job = client.query(classification_train_base_sql)\n",
        "query_job.result()\n",
        "print(\"Baseline Classification Model Training Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR4Z5tNRI3Gm",
        "outputId": "fb29c6dc-c0b0-43c3-b090-9b39b45e91af"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Retrying Training Baseline Classification Model: mgmt-544-544.us_flights_kaggle.flight_diverted_model_base...\n",
            "Baseline Classification Model Training Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2B. Corrected Evaluation Code\n",
        "CLASSIFICATION_MODEL_BASE = \"mgmt-544-544.us_flights_kaggle.flight_diverted_model_base\"\n",
        "\n",
        "classification_eval_sql = f\"\"\"\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.EVALUATE(MODEL `{CLASSIFICATION_MODEL_BASE}`)\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nEvaluating Baseline Classification Model...\")\n",
        "df_classification_eval = client.query(classification_eval_sql).to_dataframe()\n",
        "\n",
        "print(\"\\n--- Baseline Classification Model Evaluation ---\")\n",
        "# Focus on the required metrics\n",
        "print(df_classification_eval[['precision', 'recall', 'accuracy', 'f1_score']])\n",
        "\n",
        "print(\"\\nAttempting to print Confusion Matrix:\")\n",
        "try:\n",
        "    # Try the most common lowercase column name\n",
        "    print(df_classification_eval.at[0, 'confusion_matrix'])\n",
        "except KeyError:\n",
        "    # If the key fails, print all column names to help debug the name/case\n",
        "    print(\"\\nERROR: Could not find 'confusion_matrix' column.\")\n",
        "    print(\"Available columns in evaluation results are:\")\n",
        "    print(df_classification_eval.columns.tolist())\n",
        "    print(\"\\nPrinting full evaluation DataFrame for manual inspection:\")\n",
        "    print(df_classification_eval.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhxmVmL1Jr-q",
        "outputId": "af15541e-156e-44d6-af58-9f0def93bea3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Baseline Classification Model...\n",
            "\n",
            "--- Baseline Classification Model Evaluation ---\n",
            "   precision  recall  accuracy  f1_score\n",
            "0        0.0     0.0  0.997333       0.0\n",
            "\n",
            "Attempting to print Confusion Matrix:\n",
            "\n",
            "ERROR: Could not find 'confusion_matrix' column.\n",
            "Available columns in evaluation results are:\n",
            "['precision', 'recall', 'accuracy', 'f1_score', 'log_loss', 'roc_auc']\n",
            "\n",
            "Printing full evaluation DataFrame for manual inspection:\n",
            "                  0\n",
            "precision  0.000000\n",
            "recall     0.000000\n",
            "accuracy   0.997333\n",
            "f1_score   0.000000\n",
            "log_loss   0.018001\n",
            "roc_auc    0.725510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ✅ Final Working ML.PREDICT Query (Step 2C - Structural Fix)\n",
        "\n",
        "CLASSIFICATION_MODEL_BASE = \"mgmt-544-544.us_flights_kaggle.flight_diverted_model_base\"\n",
        "THRESHOLD_VALUE = 0.75\n",
        "PROB_ARRAY_COLUMN = \"predicted_is_diverted_probs\" # Name of the ARRAY column\n",
        "\n",
        "threshold_predict_sql = f\"\"\"\n",
        "SELECT\n",
        "  -- 3. Use the extracted probability (prob_value) to apply the custom threshold\n",
        "  CASE\n",
        "    WHEN prob_data.prob > {THRESHOLD_VALUE} THEN TRUE\n",
        "    ELSE FALSE\n",
        "  END AS predicted_is_diverted_custom,\n",
        "  prob_data.prob AS actual_probability\n",
        "FROM\n",
        "  ML.PREDICT(\n",
        "    MODEL `{CLASSIFICATION_MODEL_BASE}`,\n",
        "    (\n",
        "      -- 1. Input data subquery with explicit CASTING\n",
        "      SELECT\n",
        "        CAST(DepDelay AS INT64) AS DepDelay,\n",
        "        CAST(distance AS INT64) AS distance,\n",
        "        CAST(Reporting_Airline AS STRING) AS Reporting_Airline,\n",
        "        CAST(origin AS STRING) AS origin,\n",
        "        CAST(dest AS STRING) AS dest,\n",
        "        CAST(dayofweek AS INT64) AS dayofweek\n",
        "      FROM `mgmt-544-544.us_flights_kaggle.flights`\n",
        "      LIMIT 1000\n",
        "    )\n",
        "  ) AS t\n",
        "-- 2. UNNEST the probability array to extract the probability for the TRUE label\n",
        "CROSS JOIN\n",
        "  UNNEST(t.{PROB_ARRAY_COLUMN}) AS prob_data\n",
        "-- Filter to look only at predictions where the probability is above the threshold\n",
        "WHERE\n",
        "  prob_data.label IS TRUE AND prob_data.prob > {THRESHOLD_VALUE}\n",
        "\"\"\"\n",
        "\n",
        "print(f\"\\nRe-running ML.PREDICT with Final Structural Fix (UNNESTING)...\")\n",
        "# Execute the query and fetch results\n",
        "df_threshold_predict = client.query(threshold_predict_sql).to_dataframe()\n",
        "\n",
        "print(\"\\n--- Predictions at Custom Threshold (0.75) ---\")\n",
        "print(f\"Total rows considered: 1000\")\n",
        "print(f\"Number of flights predicted as DIVERTED (True) at 0.75 threshold: {len(df_threshold_predict)}\")\n",
        "print(\"Sample of high-confidence predictions (Predicted = TRUE):\")\n",
        "print(df_threshold_predict.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kUq8ZoqJ_fL",
        "outputId": "00c8fd7f-c9d1-43dc-d44f-4ae56dfa2629"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Re-running ML.PREDICT with Final Structural Fix (UNNESTING)...\n",
            "\n",
            "--- Predictions at Custom Threshold (0.75) ---\n",
            "Total rows considered: 1000\n",
            "Number of flights predicted as DIVERTED (True) at 0.75 threshold: 0\n",
            "Sample of high-confidence predictions (Predicted = TRUE):\n",
            "Empty DataFrame\n",
            "Columns: [predicted_is_diverted_custom, actual_probability]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3"
      ],
      "metadata": {
        "id": "GYOeUsRhK-CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ✅ Corrected Step 3A: Training Engineered Classification Model (No TRANSFORM)\n",
        "\n",
        "CLASSIFICATION_MODEL_ENGINEERED = \"mgmt-544-544.us_flights_kaggle.flight_diverted_model_engineered\"\n",
        "\n",
        "classification_train_engineered_sql = f\"\"\"\n",
        "CREATE OR REPLACE MODEL\n",
        "  `{CLASSIFICATION_MODEL_ENGINEERED}`\n",
        "OPTIONS\n",
        "  (model_type='LOGISTIC_REG',\n",
        "    input_label_cols=['is_diverted'],\n",
        "    data_split_method='AUTO_SPLIT'\n",
        "  ) AS\n",
        "SELECT\n",
        "  -- Feature 1: Create a ‘route’ feature\n",
        "  CONCAT(origin, '-', dest) AS route,\n",
        "\n",
        "  -- Feature 2: Bucketize dep_delay\n",
        "  CASE\n",
        "    WHEN DepDelay <= -15 THEN 'early'\n",
        "    WHEN DepDelay > -15 AND DepDelay <= 15 THEN 'on_time'\n",
        "    WHEN DepDelay > 15 AND DepDelay <= 45 THEN 'minor_delay'\n",
        "    WHEN DepDelay > 45 AND DepDelay <= 90 THEN 'moderate_delay'\n",
        "    ELSE 'major_delay'\n",
        "  END AS dep_delay_bucketized,\n",
        "\n",
        "  -- Original Features\n",
        "  distance,\n",
        "  Reporting_Airline,\n",
        "  dayofweek,\n",
        "\n",
        "  -- The Label (using the corrected method)\n",
        "  (diverted = 1) AS is_diverted\n",
        "FROM\n",
        "  `mgmt-544-544.us_flights_kaggle.flights`\n",
        "-- Important: Ensure all fields used in the SELECT are NOT NULL\n",
        "WHERE\n",
        "  diverted IS NOT NULL\n",
        "  AND DepDelay IS NOT NULL\n",
        "  AND distance IS NOT NULL\n",
        "  AND Reporting_Airline IS NOT NULL\n",
        "  AND origin IS NOT NULL\n",
        "  AND dest IS NOT NULL\n",
        "  AND dayofweek IS NOT NULL\n",
        "\"\"\"\n",
        "\n",
        "print(f\"\\nRetrying Training Engineered Classification Model (No TRANSFORM): {CLASSIFICATION_MODEL_ENGINEERED}...\")\n",
        "# Execute the query (this may take several minutes)\n",
        "query_job = client.query(classification_train_engineered_sql)\n",
        "query_job.result()\n",
        "print(\"Engineered Classification Model Training Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSbxfrHLK_Pc",
        "outputId": "ba4242fb-3c8b-4382-b7e2-c4f99e07fa47"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Retrying Training Engineered Classification Model (No TRANSFORM): mgmt-544-544.us_flights_kaggle.flight_diverted_model_engineered...\n",
            "Engineered Classification Model Training Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3B. Evaluate the Engineered Model\n",
        "CLASSIFICATION_MODEL_ENGINEERED = \"mgmt-544-544.us_flights_kaggle.flight_diverted_model_engineered\"\n",
        "\n",
        "engineered_eval_sql = f\"\"\"\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.EVALUATE(MODEL `{CLASSIFICATION_MODEL_ENGINEERED}`)\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nEvaluating Engineered Model...\")\n",
        "# Execute the query and fetch results\n",
        "df_engineered_eval = client.query(engineered_eval_sql).to_dataframe()\n",
        "\n",
        "print(\"\\n--- Engineered Model Evaluation ---\")\n",
        "# Print the key metrics for comparison\n",
        "print(df_engineered_eval[['precision', 'recall', 'accuracy', 'f1_score', 'roc_auc']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxjAKk9AMRc9",
        "outputId": "b0480c76-c760-47fb-8756-36246e6a73ab"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Engineered Model...\n",
            "\n",
            "--- Engineered Model Evaluation ---\n",
            "   precision  recall  accuracy  f1_score   roc_auc\n",
            "0        0.0     0.0  0.997806       0.0  0.621357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key takeaway is the increase in $\\text{ROC AUC}$ from the baseline (which is essentially random guessing at $0.5$) to $0.6214$. This confirms that the engineered features (route and dep_delay_bucketized) successfully added predictive power.However, the persistent $0.0$ values for Precision and Recall demonstrate that the model is still not confident enough to make any positive predictions (diverted=TRUE) above the default $0.5$ threshold, due to the extreme class imbalance."
      ],
      "metadata": {
        "id": "_g9SfnW7Mcvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4"
      ],
      "metadata": {
        "id": "jlVxpToNN0Hk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cost and Scale Analysis\n",
        "\n",
        "The two primary considerations for deploying the flight diversion prediction system are managing the economic cost of prediction errors and ensuring the technical scalability of the solution.\n",
        "\n",
        "A. Cost of Errors\n",
        "\n",
        "The prediction of flight diversion is an asymmetric risk problem. The False Negative (failing to predict an actual diversion) is the single most destructive error, leading to massive operational chaos, compensatory costs, and fines. This cost far outweighs the expense of a False Positive (a false alarm). To mitigate the catastrophic cost of False Negatives, the prediction threshold must be significantly lowered from the default 0.5 to prioritize Recall, thereby maximizing the capture rate of true diversion events, while accepting a higher number of False Positives.\n",
        "\n",
        "B. Scalability and Technical Implementation\n",
        "\n",
        "BigQuery ML offers a scalable foundation, but real-time operation requires specific cloud architecture and ongoing costs:\n",
        "\n",
        "Model Hosting: The model must be deployed to a dedicated service like Vertex AI, incurring fixed hourly hosting fees plus transaction fees for each prediction.\n",
        "\n",
        "Real-Time Data: Generating immediate predictions requires complex data pipelines (e.g., Cloud Pub/Sub or Dataflow) to handle streaming data, increasing operational complexity and expense.\n",
        "\n",
        "Continuous Retraining: To maintain accuracy against changing operational and weather patterns, the BQML model must be automatically re-trained daily or weekly, creating an ongoing computational cost based on data volume.\n",
        "\n",
        "C. Final Recommendation\n",
        "\n",
        "The final recommendation is to deploy the Engineered Model due to its confirmed superiority in the ROC AUC metric. For operational safety, the prediction threshold should be set at an aggressively low level, such as 0.1, on the Vertex AI endpoint. This setting ensures maximum operational preparedness by minimizing False Negatives, thereby preventing the highest-cost operational failures."
      ],
      "metadata": {
        "id": "aAXRj-kHN0so"
      }
    }
  ]
}