{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpF6MUwKN2VD"
      },
      "source": [
        "# Lab 9: Final Project Architecture Workshop (Blueprint)\n",
        "Date generated: 2025-08-21"
      ],
      "id": "zpF6MUwKN2VD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7Qu67Q6N2VE"
      },
      "source": [
        "Use this as your *structured design doc*. Replace all placeholders with your team’s plan."
      ],
      "id": "F7Qu67Q6N2VE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLdV2VJPN2VF"
      },
      "source": [
        "## Section 1 — Business Problem (1 paragraph)\n",
        "We will build a real-time social media sentiment analysis system that helps marketing and product teams detect changes in public sentiment about our top product within minutes. The system will surface urgent negative trends for rapid response, automatically tag high-impact posts (such as ones with high follower counts or high engagement), and provide historical context so product managers can prioritize bug fixes, feature improvements, and PR responses."
      ],
      "id": "uLdV2VJPN2VF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ddkR6R6N2VF"
      },
      "source": [
        "## Section 2 — Data Sources (batch + streaming) with access details\n",
        "Batch (historical):\n",
        "historical_twitter_100k.csv — 100,000 historical tweets collected between 2023-01-01 and 2024-12-31. Columns: post_id, created_at (ISO 8601 UTC), user_id, text, label_sentiment (negative|neutral|positive), platform, language, retweet_count, like_count, reply_count, user_followers, user_account_age_days.\n",
        "Stored in: Cloud Storage bucket gs://final-project-aurora-data/historical/.\n",
        "Streaming (live):\n",
        "Twitter/X API v2 — filtered stream (Bearer token): provides live public tweets matching brand-related rules. Stream fields: id, created_at, text, author_id, lang, public_metrics (retweets, likes, replies), geo (where available).\n",
        "Optional vendor stream (Brandwatch / Meltwater / Mention): webhook pushing brand mentions to our ingestion endpoint for broader coverage beyond Twitter. For compliance and privacy, we will only store and process public posts and will follow platform TOS. Any PII (personal data in text) will be redacted before persistent storage and flagged for manual review if required.\n"
      ],
      "id": "0ddkR6R6N2VF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCaB7RpFN2VF"
      },
      "source": [
        "## Section 3 — Cloud Architecture (diagram + narrative)\n",
        "ASCII draft:\n",
        "[API] -> [Cloud Function producer] -> [Pub/Sub topic] -> [Dataflow template] -> [BigQuery] -> [Looker]\n",
        "GCP Project & Resources (concrete names used in our build):\n",
        "\n",
        "GCP Project ID: final-sentiment-aurora-2025\n",
        "\n",
        "Cloud Storage bucket: gs://final-project-aurora-data\n",
        "\n",
        "BigQuery dataset: final_project_aurora\n",
        "\n",
        "Pub/Sub topic: projects/final-sentiment-aurora-2025/topics/twitter-stream\n",
        "\n",
        "Dataflow job name prefix: aurora-dataflow-.\n",
        "\n",
        "Ingest (Streaming + Batch):\n",
        "\n",
        "Historical CSV historical_twitter_100k.csv uploaded to gs://final-project-aurora-data/historical/ and loaded once into BigQuery table final_project_aurora.raw_twitter_posts using a one-time bq load job.\n",
        "Live tweets arrive via Twitter filtered stream. A lightweight ingestion service runs on Cloud Run (twitter-ingest) that establishes the persistent connection (or receives webhook events from vendor streams). The service publishes incoming JSON messages to Pub/Sub topic twitter-stream.\n",
        "\n",
        "Stream buffer & pre-processing:\n",
        "\n",
        "Pub/Sub acts as durable buffer and decouples ingestion from processing.\n",
        "Topics:\n",
        "\n",
        "- twitter-stream (primary) and twitter-stream-deadletter (DLQ).\n",
        "\n",
        "- Dataflow (Apache Beam, streaming) job aurora-dataflow-clean subscribes to twitter-stream.\n",
        "\n",
        "Responsibilities:\n",
        "\n",
        "Validate incoming JSON schema and route malformed messages to the DLQ.\n",
        "Normalize timestamps to UTC and parse language tags.\n",
        "Compute lightweight features: text_length, has_hashtag (bool), has_mention (bool), has_url (bool), hashtags_count, mentions_count, is_retweet.\n",
        "Enrich with user metadata if available (followers count, account age), and compute engagement_score = retweet_count*1 + reply_count*1.5 + like_count*0.5.\n",
        "Batch and buffer inserts to BigQuery for cost-effectiveness.\n",
        "\n",
        "ML enrichment & scoring:\n",
        "Primary sentiment scoring happens in two parallel paths:\n",
        "Low-latency path: Dataflow calls a lightweight local BQML microservice (deployed as a prediction endpoint in BigQuery or Cloud Run) for immediate sentiment prediction for every message (used for dashboarding and alerts). This path avoids external API rate limits.\n",
        "High-fidelity path: A sampled subset (configurable, default 20%) and high-impact posts (e.g., user_followers > 10000 or engagement_score > 50) are sent to the Natural Language AI API for richer sentiment scores and entity extraction. Results are merged back into BigQuery for model training and deep analysis.\n",
        "\n",
        "Storage & serving:\n",
        "Processed streaming records written to BigQuery table final_project_aurora.processed_tweets (partitioned by DATE(created_at) and clustered by label_sentiment, platform). Use streaming inserts with fallback to batched load via Cloud Storage for resilience.\n",
        "Historical CSV data initially loaded into final_project_aurora.historical_tweets and then normalized into the processed table schema.\n",
        "\n",
        "Modeling & retraining:\n",
        "Use BigQuery ML to train the baseline classification model final_project_aurora.models.sentiment_bqml_v1 (see SQL example below).\n",
        "Model retraining cadence: weekly (every Sunday 02:00 UTC) triggered by Cloud Scheduler invoking a Cloud Function which executes a CREATE OR REPLACE MODEL BigQuery job. Retrain earlier if data drift is detected.\n",
        "\n",
        "Visualization & alerting:\n",
        "Looker Studio dashboard named Aurora Sentiment Monitor connects directly to BigQuery (final_project_aurora.processed_tweets) for live visualizations.\n",
        "Cloud Monitoring / Alerting: alert rules defined for operational metrics (Dataflow lag > 5 minutes, Pub/Sub unacked messages > threshold) and business KPIs (negative % in 15-min window > 30%). Alerts sent to Slack channel #aurora-alerts and PagerDuty.\n",
        "\n",
        "Concrete example BigQuery table names and model names:\n",
        "\n",
        "final_project_aurora.raw_twitter_posts (raw records)\n",
        "\n",
        "final_project_aurora.processed_tweets (cleaned+enriched records)\n",
        "\n",
        "final_project_aurora.labels.manual_labeled (human-labeled samples for evaluation)\n",
        "\n"
      ],
      "id": "BCaB7RpFN2VF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLKDtS46N2VG"
      },
      "source": [
        "## Section 4 — ML Plan (BQML): target, features, metric, scoring mode\n",
        "Problem formulation:\n",
        "\n",
        "Primary task: Multiclass classification to predict label_sentiment in {negative, neutral, positive} for each post.\n",
        "\n",
        "Secondary task (optional): Regression to predict continuous sentiment score in [-1,1] if we want finer-grained scoring.\n",
        "\n",
        "Training data and split:\n",
        "\n",
        "Use the 100k historical tweets (historical_twitter_100k.csv) as the primary labeled dataset.\n",
        "\n",
        "Supplement training data with human-labeled streaming samples kept in labels.manual_labeled (target 5,000 labeled streaming samples gathered over the first 6 weeks).\n",
        "\n",
        "Train/val/test split: 80/10/10.\n",
        "\n",
        "Features (final, concrete list):\n",
        "\n",
        "text_length (int)\n",
        "\n",
        "hashtags_count (int)\n",
        "\n",
        "mentions_count (int)\n",
        "\n",
        "user_followers (int)\n",
        "\n",
        "engagement_score (float)\n",
        "\n",
        "platform (string / categorical)\n",
        "\n",
        "language (string / categorical)\n",
        "\n",
        "hour_of_day (int)\n",
        "\n",
        "day_of_week (int)\n",
        "\n",
        "has_negative_keyword (boolean)\n",
        "\n",
        "avg_sentiment_last_15m (float) — rolling feature computed by scheduled SQL or within Dataflow windowing (optional)\n",
        "\n",
        "embedding_vector (REPEATED FLOAT) — optional; precomputed embeddings stored in a separate table and joined if required.\n",
        "\n",
        "Model selection & evaluation:\n",
        "\n",
        "Baseline: boosted_tree_classifier in BQML.\n",
        "\n",
        "Evaluation metrics: accuracy, precision/recall per class, macro F1, and confusion matrix. Store eval results in final_project_aurora.model_evals.\n",
        "Use ML.EXPLAIN to surface top features driving predictions.\n",
        "\n",
        "Retraining & deployment:\n",
        "Retrain weekly or when drift detected (automatic detection via statistical tests comparing recent vs baseline distributions stored in BigQuery).\n",
        "Deploy predictions by writing to table final_project_aurora.predictions_streaming and exposing a prediction summary table optimized for Looker Studio.\n",
        "\n"
      ],
      "id": "iLKDtS46N2VG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ArPEcdqN2VG"
      },
      "source": [
        "## Section 5 — Dashboard KPIs (3–5) with definitions and SQL sources\n",
        "Dashboard name: Aurora Sentiment Monitor\n",
        "\n",
        "Real-time Sentiment Score (15-min rolling average) — rolling mean sentiment score (or % positive minus % negative) with 1–5 minute latency.\n",
        "Alert threshold: negative % in last 15 minutes > 30% triggers a page-level alert and Slack notification.\n",
        "Mentions Volume (posts/hour) — total incoming posts mentioning tracked keywords; helps separate volume spikes from sentiment shifts.\n",
        "\n",
        "Example alert: mentions/hour increases by >300% relative to baseline.\n",
        "\n",
        "Sentiment Distribution — stacked bar / donut showing % positive / neutral / negative for selected time window.\n",
        "Top Negative Themes — table of top 10 keywords/entities associated with negative posts (counts & examples).\n",
        "Model Health & Data Drift — sample model accuracy (from labeled streaming samples), and a drift indicator (e.g., KL divergence for text length or language distribution vs baseline).\n"
      ],
      "id": "8ArPEcdqN2VG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDjSs7Q2N2VG"
      },
      "source": [
        "## Section 6 — Risks & Mitigations (Devil’s Advocate) + Prompt\n",
        "Biggest risk: Relying on external streaming APIs (Twitter/X) and the Natural Language API for high-fidelity scoring creates two correlated single points of failure: (1) data coverage and continuity risk (API outages, access revocations, or rule pruning), and (2) cost/latency risk from third-party scoring at scale.\n"
      ],
      "id": "EDjSs7Q2N2VG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydrUbsqoN2VH"
      },
      "source": [
        "## Section 7 — Milestones & Ownership (30/60/90 or weekly)\n",
        "Week 1 (Day 1–7): Foundation & Data Setup\n",
        "\n",
        "Finalize project objective and research question\n",
        "\n",
        "Confirm dataset (German Credit)\n",
        "\n",
        "Import data, perform cleaning, create train/test split\n",
        "\n",
        "Initial EDA: summary statistics, target distribution, correlation checks\n",
        "Owner: Analyst A\n",
        "\n",
        "Week 2 (Day 8–14): Modeling & Baselines\n",
        "\n",
        "Build logistic regression baseline\n",
        "\n",
        "Fit KNN, Decision Tree, and Random Forest models\n",
        "\n",
        "Evaluate accuracy, AUC, confusion matrices\n",
        "\n",
        "Begin tuning hyperparameters\n",
        "Owner: Analyst B\n",
        "\n",
        "Week 3 (Day 15–21): Optimization & Interpretability\n",
        "\n",
        "Hyperparameter tuning across all models\n",
        "\n",
        "Finalize best-performing model\n",
        "\n",
        "Create model interpretation outputs (feature importance, SHAP, charts)\n",
        "\n",
        "Draft visuals for presentation\n",
        "Owner: Analyst A\n",
        "\n",
        "Week 4 (Day 22–30): Finalization & Deliverables\n",
        "\n",
        "Finalize presentation slides\n",
        "\n",
        "Write executive summary\n",
        "\n",
        "Produce final report (methods, results, recommendations)\n",
        "\n",
        "Prepare 8-minute presentation script\n",
        "Owner: Analyst B"
      ],
      "id": "ydrUbsqoN2VH"
    }
  ]
}